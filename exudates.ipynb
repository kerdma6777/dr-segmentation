{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features:\n",
    "* for both hard and soft exudates:\n",
    "    * total area\n",
    "    * number of exudates\n",
    "    * average area of exudate\n",
    "* any intensity data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import hashlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "27\n",
      "26\n",
      "14\n",
      "54\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "## Setting Paths\n",
    "train_path = \"/Users/KateB/BMI260/project/IEEE_Data/Segmentation/1. Original Images/a. Training Set\"\n",
    "test_path = \"/Users/KateB/BMI260/project/IEEE_Data/Segmentation/1. Original Images/b. Testing Set\"\n",
    "\n",
    "train_photos = os.listdir(train_path)\n",
    "test_photos = os.listdir(test_path)\n",
    "\n",
    "train_seg_path = \"IEEE_Data/Segmentation/2. All Segmentation Groundtruths/a. Training Set\"\n",
    "test_seg_path = \"IEEE_Data/Segmentation/2. All Segmentation Groundtruths/b. Testing Set\"\n",
    "\n",
    "train_hard_path = os.path.join(train_seg_path, \"3. Hard Exudates\")\n",
    "test_hard_path = os.path.join(test_seg_path, \"3. Hard Exudates\")\n",
    "train_soft_path = os.path.join(train_seg_path, \"4. Soft Exudates\")\n",
    "test_soft_path = os.path.join(test_seg_path, \"4. Soft Exudates\")\n",
    "train_od_path = os.path.join(train_seg_path, \"5. Optic Disc\")\n",
    "test_od_path = os.path.join(test_seg_path, \"5. Optic Disc\")\n",
    "\n",
    "\n",
    "train_hard_photos = os.listdir(train_hard_path)\n",
    "test_hard_photos = os.listdir(test_hard_path)\n",
    "train_soft_photos = os.listdir(train_soft_path)\n",
    "test_soft_photos = os.listdir(test_soft_path)\n",
    "train_od_photos = os.listdir(train_od_path)\n",
    "test_od_photos = os.listdir(test_od_path)\n",
    "\n",
    "train_photos.sort()\n",
    "test_photos.sort()\n",
    "train_hard_photos.sort()\n",
    "test_hard_photos.sort()\n",
    "train_soft_photos.sort()\n",
    "test_soft_photos.sort()\n",
    "train_od_photos.sort()\n",
    "test_od_photos.sort()\n",
    "\n",
    "print(len(train_photos))\n",
    "print(len(test_photos))\n",
    "print(len(train_soft_photos))\n",
    "print(len(test_soft_photos))\n",
    "print(len(train_od_photos))\n",
    "print(len(test_od_photos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idiot_train_path = \"/Users/KateB/BMI260/project/IEEE_Data/Disease Grading/1. Original Images/a. Training Set\"\n",
    "idiot_test_path = \"/Users/KateB/BMI260/project/IEEE_Data/Disease Grading/1. Original Images/b. Testing Set\"\n",
    "\n",
    "idiot_train_photos = os.listdir(idiot_train_path)\n",
    "idiot_test_photos = os.listdir(idiot_test_path)\n",
    "\n",
    "idiot_train_photos.sort()\n",
    "idiot_test_photos.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idiot_arrays = np.array([])\n",
    "# for i in range(0, 15):\n",
    "#     print(\"i: \", i)\n",
    "#     idiot_im = Image.open(os.path.join(idiot_train_path, idiot_train_photos[i]))\n",
    "#     idiot_arr = np.asarray(idiot_im)\n",
    "#     idiot_arrays = np.append(idiot_arrays, idiot_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e67c152ab569c77e145412b0867fdc5a e67c152ab569c77e145412b0867fdc5a\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "seg_path = os.path.join(train_path, train_photos[0])\n",
    "og_path = os.path.join(idiot_train_path, \"IDRiD_102.jpg\")\n",
    "seg_checksum = md5(seg_path)\n",
    "og_checksum = md5(og_path)\n",
    "\n",
    "print(seg_checksum, og_checksum)\n",
    "print(seg_checksum == og_checksum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "IDRiD_01.jpg IDRiD_102.jpg\n",
      "1\n",
      "IDRiD_02.jpg IDRiD_366.jpg\n",
      "2\n",
      "IDRiD_03.jpg IDRiD_369.jpg\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "good_photos = []\n",
    "for i in range(0, len(train_photos)):\n",
    "    good_photos.append(os.path.join(train_path, train_photos[i]))\n",
    "\n",
    "for i in range(0, len(test_photos)):\n",
    "    good_photos.append(os.path.join(test_path, test_photos[i]))\n",
    "    \n",
    "idiot_photos = []\n",
    "for i in range(0, len(idiot_train_photos)):\n",
    "    idiot_photos.append(os.path.join(idiot_train_path, idiot_train_photos[i]))\n",
    "\n",
    "for i in range(0, len(idiot_test_photos)):\n",
    "    idiot_photos.append(os.path.join(idiot_test_path, idiot_test_photos[i]))\n",
    "    \n",
    "\n",
    "\n",
    "matches = np.array(['seg_id', 'original_id'])\n",
    "for i in range(0, len(good_photos)):\n",
    "    print(i)\n",
    "    checksum = md5(good_photos[i])\n",
    "    \n",
    "    for j in range(0, len(idiot_photos)):\n",
    "        idiot_checksum = md5(idiot_photos[j])\n",
    "        \n",
    "#         idiot_im = Image.open(os.path.join(idiot_train_path, idiot_train_photos[j]))\n",
    "#         idiot_arr = np.asarray(idiot_im)\n",
    "        if (checksum == idiot_checksum):\n",
    "            matches = np.vstack((matches, [good_photos[i], idiot_photos[j]]))\n",
    "            print(train_photos[i], idiot_train_photos[j])\n",
    "            break\n",
    "\n",
    "            \n",
    "# for i in range(0, len(idiot_train_photos)):\n",
    "# #     im = Image.open(os.path.join(idiot_train_path, idiot_train_photos[i]))\n",
    "#     checksum = md5(os.path.join(idiot_train_path, idiot_train_photos[i]))\n",
    "#     print (checksum)\n",
    "#     im_arr = np.asarray(im)\n",
    "#     idiot_arr[:,:,i] = im_arr[:,:,0]\n",
    "#     print (i)\n",
    "    \n",
    "# for i in range(0, len(idiot_test_photos)):\n",
    "#     im = Image.open(os.path.join(idiot_test_path, idiot_test_photos[i]))\n",
    "#     im_arr = np.asarray(im)\n",
    "#     idiot_arr[:,:,i + len(idiot_train_photos)] = im_arr[:,:,0]\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "print (matches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_idiot = len(idiot_train_photos) + len(idiot_test_photos)\n",
    "print(total_idiot)\n",
    "\n",
    "\n",
    "\n",
    "# im1 = Image.open(os.path.join(idiot_train_path, idiot_train_photos[2]))\n",
    "# im1_arr = np.asarray(im1)\n",
    "# im2 = Image.open(os.path.join(idiot_train_path, idiot_train_photos[3]))\n",
    "# im2_arr = np.asarray(im2)\n",
    "# print(im1_arr.shape)\n",
    "# print(im2_arr.shape)\n",
    "\n",
    "idiot_arr = np.zeros((2848, 4288, total_idiot))\n",
    "\n",
    "# for i in range(0, len(idiot_train_photos)):\n",
    "#     im = Image.open(os.path.join(idiot_train_path, idiot_train_photos[i]))\n",
    "#     im_arr = np.asarray(im)\n",
    "#     idiot_arr[:,:,i] = im_arr[:,:,0]\n",
    "#     print (i)\n",
    "    \n",
    "# for i in range(0, len(idiot_test_photos)):\n",
    "#     im = Image.open(os.path.join(idiot_test_path, idiot_test_photos[i]))\n",
    "#     im_arr = np.asarray(im)\n",
    "#     idiot_arr[:,:,i + len(idiot_train_photos)] = im_arr[:,:,0]\n",
    "#     print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches = np.array(['seg_id', 'original_id'])\n",
    "# for i in range(10, 20):\n",
    "#     print(\"i: \", i)\n",
    "#     good_im = Image.open(os.path.join(train_path, train_photos[i]))\n",
    "#     good_arr = np.asarray(good_im)\n",
    "#     for j in range(0,len(idiot_train_photos)):\n",
    "#         idiot_im = Image.open(os.path.join(idiot_train_path, idiot_train_photos[j]))\n",
    "#         idiot_arr = np.asarray(idiot_im)\n",
    "#         if (np.array_equal(idiot_arr, good_arr)):\n",
    "#             matches = np.vstack((matches, [train_photos[i], idiot_train_photos[j]]))\n",
    "#             print(train_photos[i], idiot_train_photos[j])\n",
    "#             break\n",
    "\n",
    "# np.savetxt(\"matches.csv\", delimiter = ',', fmt = '%s')    test_arrays = np.array([])\n",
    "# for i in range(0, len(idiot_test_photos)):\n",
    "#     idiot_im = Image.open(os.path.join(idiot_test_path, idiot_test_photos[i]))\n",
    "#     idiot_arr = np.asarray(idiot_im)\n",
    "#     test_arrays = np.append(idiot_arrays, idiot_arr)\n",
    "\n",
    "print(\"finished\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_2 = matches\n",
    "print(matches_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " \n",
    "\n",
    "# test_matches = np.array(['seg_id', 'original_id'])\n",
    "# for i in range(0, len(test_photos)):\n",
    "#     print(\"starting image i: \", i)\n",
    "#     good_im = Image.open(os.path.join(test_path, test_photos[i]))\n",
    "#     good_arr = np.asarray(good_im)\n",
    "#     for j in range(0,len(idiot_test_photos)):\n",
    "#         idiot_arr = test_arrays[j]\n",
    "#         if (np.array_equal(idiot_arr, good_arr)):\n",
    "#             test_matches = np.vstack((test_matches, [test_photos[i], idiot_test_photos[j]]))\n",
    "#             break\n",
    "\n",
    "# np.savetxt(\"test_matches.csv\", delimiter = ',', fmt = '%s')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_arrays = np.array([])\n",
    "# for i in range(0, len(idiot_test_photos)):\n",
    "#     idiot_im = Image.open(os.path.join(idiot_test_path, idiot_test_photos[i]))\n",
    "#     idiot_arr = np.asarray(idiot_im)\n",
    "#     test_arrays = np.append(idiot_arrays, idiot_arr)\n",
    "\n",
    "# print(\"finished caching\")    \n",
    "\n",
    "# test_matches = np.array(['seg_id', 'original_id'])\n",
    "# for i in range(0, len(test_photos)):\n",
    "#     print(\"starting image i: \", i)\n",
    "#     good_im = Image.open(os.path.join(test_path, test_photos[i]))\n",
    "#     good_arr = np.asarray(good_im)\n",
    "#     for j in range(0,len(idiot_test_photos)):\n",
    "#         idiot_arr = test_arrays[j]\n",
    "#         if (np.array_equal(idiot_arr, good_arr)):\n",
    "#             test_matches = np.vstack((test_matches, [test_photos[i], idiot_test_photos[j]]))\n",
    "#             break\n",
    "\n",
    "# np.savetxt(\"test_matches.csv\", delimiter = ',', fmt = '%s')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get hard exudate circles\n",
    "def get_hard_exudates(arr):\n",
    "    circles = cv2.HoughCircles(arr, cv2.HOUGH_GRADIENT,1,20,param1=2,param2=10,minRadius=0,maxRadius=75)\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    return circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get soft exudate circles\n",
    "def get_soft_exudates(arr):\n",
    "    circles = cv2.HoughCircles(arr, cv2.HOUGH_GRADIENT,1.05,20,param1=2,param2=10,minRadius=0,maxRadius=75)\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    return circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get od center\n",
    "def get_od_center(i):\n",
    "    od_mask = Image.open(os.path.join(train_od_path, train_od_photos[i]))\n",
    "    od_arr = np.asarray(od_mask)\n",
    "    disc = cv2.HoughCircles(od_arr, cv2.HOUGH_GRADIENT,1,100,param1=2,param2=10,minRadius=15,maxRadius=300)\n",
    "    return (disc[0,0,0],disc[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Average from exudates to Optic Disc center\n",
    "def ave_od_distance(od_center, exudates):\n",
    "    dists = np.array([])\n",
    "    for j in exudates[0,:]:\n",
    "        dists = np.append(dists, distance.euclidean((j[0],j[1]),od_center))\n",
    "    \n",
    "    return np.average(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING DATA\n",
    "train_data = np.array(['image_id', 'percent_hard_exudates', \"num_hard_exudates\", 'average_dist_hard', \n",
    "                       'percent_soft_exudates', 'num_soft_exudates', 'average_dist_soft'])\n",
    "    \n",
    "s = 0\n",
    "for i in range(0, len(train_photos)):\n",
    "    him = Image.open(os.path.join(train_hard_path, train_hard_photos[i]))\n",
    "    him_arr = np.asarray(him)\n",
    "\n",
    "    # Get percentage\n",
    "    percent_hex = np.sum(him_arr) / (him_arr.shape[0] * him_arr.shape[1])\n",
    "    \n",
    "    # Get hard exudates\n",
    "    hard_exudates = get_hard_exudates(him_arr)\n",
    "    num_hard = hard_exudates.shape[1]\n",
    "    \n",
    "    # od_center\n",
    "    od_center = get_od_center(i)\n",
    "    \n",
    "    ## distance to optic disc\n",
    "    hard_ave_dist = ave_od_distance(od_center, hard_exudates)\n",
    "    \n",
    "    \n",
    "    ## soft exudates....\n",
    "    if ((train_photos[i][:-4]) in train_soft_photos[s]):\n",
    "        sim = Image.open(os.path.join(train_soft_path, train_soft_photos[s]))\n",
    "        sim_arr = np.asarray(sim)\n",
    "        \n",
    "        percent_sex = np.sum(sim_arr) / (sim_arr.shape[0] * sim_arr.shape[1])\n",
    "        \n",
    "        soft_exudates = get_soft_exudates(sim_arr)\n",
    "        num_soft = soft_exudates.shape[1]\n",
    "        \n",
    "        soft_ave_dist = ave_od_distance(od_center, soft_exudates)\n",
    "        \n",
    "        s += 1\n",
    "    else:\n",
    "        percent_sex = 0\n",
    "        num_soft = 0\n",
    "        soft_ave_dist = 0\n",
    "    \n",
    "    current_data = [train_photos[i], percent_hex, num_hard, hard_ave_dist, percent_sex, num_soft, soft_ave_dist]\n",
    "    train_data = np.vstack((train_data, current_data))\n",
    "    \n",
    "np.savetxt(\"train_exudate_features.csv\", train_data, delimiter = ',', fmt = \"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TESTING DATA\n",
    "\n",
    "test_data = np.array(['image_id', 'percent_hard_exudates', \"num_hard_exudates\", 'average_dist_hard', \n",
    "                       'percent_soft_exudates', 'num_soft_exudates', 'average_dist_soft'])\n",
    "    \n",
    "s = 0\n",
    "for i in range(0, len(test_photos)):\n",
    "    him = Image.open(os.path.join(test_hard_path, test_hard_photos[i]))\n",
    "    him_arr = np.asarray(him)\n",
    "\n",
    "    # Get percentage\n",
    "    percent_hex = np.sum(him_arr) / (him_arr.shape[0] * him_arr.shape[1])\n",
    "    \n",
    "    # Get hard exudates\n",
    "    hard_exudates = get_hard_exudates(him_arr)\n",
    "    num_hard = hard_exudates.shape[1]\n",
    "    \n",
    "    # od_center\n",
    "    od_center = get_od_center(i)\n",
    "    \n",
    "    ## distance to optic disc\n",
    "    hard_ave_dist = ave_od_distance(od_center, hard_exudates)\n",
    "    \n",
    "    \n",
    "    ## soft exudates....\n",
    "    if ((test_photos[i][:-4]) in test_soft_photos[s]):\n",
    "        sim = Image.open(os.path.join(test_soft_path, test_soft_photos[s]))\n",
    "        sim_arr = np.asarray(sim)\n",
    "        \n",
    "        percent_sex = np.sum(sim_arr) / (sim_arr.shape[0] * sim_arr.shape[1])\n",
    "        \n",
    "        soft_exudates = get_soft_exudates(sim_arr)\n",
    "        num_soft = soft_exudates.shape[1]\n",
    "        \n",
    "        soft_ave_dist = ave_od_distance(od_center, soft_exudates)\n",
    "        \n",
    "        s += 1\n",
    "    else:\n",
    "        percent_sex = 0\n",
    "        num_soft = 0\n",
    "        soft_ave_dist = 0\n",
    "    \n",
    "    current_data = [test_photos[i], percent_hex, num_hard, hard_ave_dist, percent_sex, num_soft, soft_ave_dist]\n",
    "    test_data = np.vstack((test_data, current_data))\n",
    "    \n",
    "np.savetxt(\"test_exudate_features.csv\", test_data, delimiter = ',', fmt = \"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.imshow(him)\n",
    "for j in circles[0,:]:\n",
    "    ax.add_artist(plt.Circle((j[0],j[1]),j[2], color='r', fill = False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading in photos\n",
    "# will need to loop through this at some point\n",
    "im = Image.open(os.path.join(train_hard_path,train_hard_photos[0]))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "#im2 = Image.open(os.path.join(train_hard_path, train_hard_photos[1]))\n",
    "im2 = Image.open(os.path.join(train_hard_path, \"IDRiD_03_EX.tif\"))\n",
    "plt.imshow(im2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_arr = np.asarray(im)\n",
    "ex_pixels = np.sum(im_arr)\n",
    "total_pixels = im_arr.shape[0] * im_arr.shape[1]\n",
    "print(ex_pixels, total_pixels, ex_pixels / total_pixels * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with another\n",
    "im2_arr = np.asarray(im2)\n",
    "ex2_pixels = np.sum(im2_arr)\n",
    "total2_pixels = im2_arr.shape[0] * im2_arr.shape[1]\n",
    "print(ex2_pixels, total2_pixels, ex2_pixels / total2_pixels * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try circle Hough Transform\n",
    "# convert to grayscale\n",
    "# \n",
    "circles = cv2.HoughCircles(im2_arr, cv2.HOUGH_GRADIENT,1,20,param1=2,param2=10,minRadius=0,maxRadius=75)\n",
    "circles = np.uint16(np.around(circles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circles.shape)\n",
    "print(im2_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try with matplotlib\n",
    "print((circles[0,0,0],circles[0,0,1]),circles[0,0,2])\n",
    "fix,ax = plt.subplots()\n",
    "plt.imshow(im2_arr)\n",
    "for i in circles[0,:]:\n",
    "    ax.add_artist(plt.Circle((i[0],i[1]),i[2], color='r', fill = False))\n",
    "\n",
    "#ax.add_artist(circle1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Find distances to focal center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
